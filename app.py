import streamlit as st
import fitz  # PyMuPDF
import tiktoken
from openai import OpenAI

# Cliente OpenAI con clave segura desde Streamlit Cloud
client = OpenAI(api_key=st.secrets["openai_api_key"])

# Tokenizador GPT-4 Turbo (usamos cl100k_base que es compatible)
encoding = tiktoken.get_encoding("cl100k_base")

# LÃ­mite real del modelo gpt-4-turbo (entrada + salida)
MAX_TOTAL_TOKENS = 128000
MAX_OUTPUT_TOKENS = 6000  # tokens reservados para respuesta
MAX_INPUT_TOKENS = MAX_TOTAL_TOKENS - MAX_OUTPUT_TOKENS

# --- FunciÃ³n para contar tokens ---
def contar_tokens(texto):
    return len(encoding.encode(texto))

# --- FunciÃ³n para extraer texto de PDF ---
def extract_text_from_pdf(uploaded_file):
    with fitz.open(stream=uploaded_file.read(), filetype="pdf") as doc:
        text = ""
        for page in doc:
            text += page.get_text()
    return text

# --- Generar anÃ¡lisis clÃ­nico por secciÃ³n ---
def generar_analisis_clinico(texto_total, seccion_objetivo):
    if seccion_objetivo == "Todo el artÃ­culo":
        objetivo_prompt = "analiza el artÃ­culo completo"
    else:
        objetivo_prompt = f"analiza exclusivamente la secciÃ³n de {seccion_objetivo.lower()}"

    prompt = f"""
ActÃºa como mÃ©dico especialista en medicina materno-fetal.

Tienes a continuaciÃ³n el contenido de un artÃ­culo cientÃ­fico extraÃ­do de un PDF:

{texto_total}

Por favor, {objetivo_prompt} y genera un informe profesional para revisiÃ³n por especialistas clÃ­nicos. El informe debe estar estructurado, enfocado en evidencia mÃ©dica clara, y ser Ãºtil para discusiÃ³n acadÃ©mica o aplicaciÃ³n clÃ­nica.

Incluye solo lo que corresponda a la secciÃ³n seleccionada si asÃ­ se indica.
"""
    respuesta = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=MAX_OUTPUT_TOKENS
    )
    return respuesta.choices[0].message.content

# --- Pregunta personalizada ---
def responder_pregunta(texto_total, pregunta):
    prompt = f"""
Eres un asistente clÃ­nico experto en medicina materno-fetal.

Con base en el siguiente contenido mÃ©dico extraÃ­do de varios artÃ­culos cientÃ­ficos:

{texto_total}

Responde la siguiente pregunta del usuario con base en la evidencia presentada:

PREGUNTA: {pregunta}
"""
    respuesta = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=3000
    )
    return respuesta.choices[0].message.content

# --- Interfaz principal ---
st.set_page_config(page_title="FLASOG 2025 - AnÃ¡lisis de Literatura MÃ©dica", layout="centered")

st.title("ğŸ“˜ AnÃ¡lisis de Literatura MÃ©dica FLASOG 2025")
st.markdown("### ğŸ§  IA aplicada al anÃ¡lisis de artÃ­culos clÃ­nicos extensos")
st.info("Modelo en uso: gpt-4-turbo Â· LÃ­mite: 128k tokens")

uploaded_files = st.file_uploader("ğŸ“„ Sube uno o mÃ¡s artÃ­culos mÃ©dicos en PDF", type="pdf", accept_multiple_files=True)

seccion_objetivo = st.radio("Selecciona la secciÃ³n a analizar:",
                            ["Todo el artÃ­culo", "MetodologÃ­a", "Resultados", "Conclusiones"], index=0)

texto_total = ""

if uploaded_files:
    for archivo in uploaded_files:
        texto_total += extract_text_from_pdf(archivo) + "\n\n"

    token_count = contar_tokens(texto_total)
    st.info(f"ğŸ”¢ Tokens estimados: {token_count}")

    if token_count > MAX_INPUT_TOKENS:
        st.warning("âš ï¸ El texto fue recortado para ajustarse al lÃ­mite del modelo (mÃ¡x. 100k tokens de entrada).")
        tokens = encoding.encode(texto_total)
        texto_total = encoding.decode(tokens[:MAX_INPUT_TOKENS])
        st.info(f"âœ‚ï¸ Texto recortado a {contar_tokens(texto_total)} tokens")

    if st.button("ğŸ“‘ Generar anÃ¡lisis clÃ­nico"):
        with st.spinner("ğŸ§  Procesando con IA..."):
            resultado = generar_analisis_clinico(texto_total, seccion_objetivo)
            st.subheader("ğŸ“ Informe clÃ­nico generado:")
            st.write(resultado)
            st.download_button("ğŸ’¾ Descargar informe", resultado, file_name="informe_clinico.txt")

    st.markdown("---")
    st.subheader("ğŸ’¬ Haz una pregunta personalizada")

    pregunta = st.text_input("Escribe tu pregunta aquÃ­:")
    if st.button("â“ Responder"):
        if pregunta.strip():
            with st.spinner("ğŸ’¡ Respondiendo..."):
                respuesta = responder_pregunta(texto_total, pregunta)
                st.markdown("### âœ… Respuesta:")
                st.write(respuesta)
        else:
            st.warning("Escribe una pregunta vÃ¡lida.")
